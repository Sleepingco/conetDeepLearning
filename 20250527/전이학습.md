전이학습
한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식

딥러닝의 '이미지 분류' 문제를 해결하는데 사용했던 신경망을
이용 다른 데이터 셋 혹은 다른 문제(task)에 적용 시켜 푸는 것을 의미
ImageNet을 학습시킨 cnn구조는 다른 딥러닝 프레임워크에서 api로 사용할 수 있다

신경망 학습을 위해서는 대량의 데이터셋이 필요한데 가장 대표적으로 ImageNet

Traditional ML
Isolated, single task learning:
• Knowledge is not retained or
accumulated. Learning is performed
w.o. considering past learned
knowledge in other tasks

Transfer Learning
Learning of a new tasks relies on
the previous learned tasks:
Ο Learning process can be faster, more
accurate and/or need less training data

pretrained model = feture-extractor(cnn) + classifier

feature extractor: 입력 데이터에서 중요한 특정, 표현을 추출하는 역할.
이미지 분류의 경우, 이미지 텍스처,모양,색상등 시각적 특징을 추출
Classifier:feature extractor로부터 추출된 특징을 기반으로 입력데이터를 분류하는 역할 이미지 분류의 경우, classifier는 추출된 특징을 사용하여 이미지가 어떤 클래스에 속하는지 예측

TensorFlow의 주요 pretrained model :  
이미지 분류, 객체 감지, 자연어 처리 등 다양한 작업에 활용

1. VGG16/VGG19 : 이미지 분류를 위한 CNN (Convolutional Neural Network). ImageNet 데이터셋을  
기반으로 다양한 객체 및 동물을 분류를 수행.

2. ResNet50/ResNet101 : 대규모 데이터셋에서 다양한 객체 및 동물을 분류.

3. MobileNet : 경량화된 CNN 아키텍처로, 모바일 및 임베디드 장치에서의 실시간 이미지 분류 작업에 특화.  
작은 크기와 빠른 속도로 객체 분류를 수행.

4. SSD (Single Shot MultiBox Detector): 객체 감지 및 객체 기반 작업에 사용.

5. BERT (Bidirectional Encoder Representations from Transformers): Transformer 기반 아키텍처로,  
문장의 의미와 문맥을 이해하는 데에 탁월한 성능. 텍스트 분류, 문장 유사도 측정, 개체명 인식 등 다양한  
자연어 처리 작업에 활용.

=> 적용할 데이터에 대해 다양한 모델의 사용하여 최적의 모델과 환경을 선택 !!


Fine-tuning : pretrained model의 일부 레이어를 고정하고  
일부 레이어를 재훈련하여 새로운 작업에 적합하도록 조정

1. 기존 모델 가져오기: ImageNet에서 사전 훈련된 모델을 다운로드/API

2. 레이어 동결(freeze): low level feature trained model의 레이어 동결, 가중치 고정

3. 새로운 레이어 추가(fine tuning): 새로운 작업에 맞게 추가적인 레이어를 모델에 추가.

4. 재훈련(Training): 새로운 레이어를 초기화, 모델을 재훈련. 새로운 레이어들의 가중치를 학습.
