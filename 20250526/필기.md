합성곱 후의 출력 사이즈 계산
convolution 연산을 수행한 후의 결과물 크기는
입력 데이터의 크기, 필터 크기, 패딩의 유무, 스트라이드(stride)의 값에 의해 결정

패팅을 적용하지 않은 경우: 출력 크기 = (입력크기 = 필터크기)/스트라이드 +1
패딩을 적용한 경우: 출력 크기 = (입력크기 - 필터 크기 +2 * 패딩)/ 스트라이드 +1

초기 필터의 구성
합성곱 신경망에서 필터는 신경망의 가중치와 유사한 역할
필터는 입력 데이터와의 합성곱 연산을 수행하며,
필터의 가중치는 입력 데이터의 특정 패턴을 감지하고 추출하는 데 사용
초기 필터의 가중치는 작은 무작위 숫자로 초기화
모델이 학습을 시작할 때 각 필터가 입력 데이터의 특징을 잘 캡처할 수 있도록 초기 설정 제공
모델은 학습 과정에서 가중치를 조정하여 입력 데이터의 특징을 더욱 정확하게 추출
사전 훈련된 모델을 사용하는 경우
사전 훈련된 모델은 이미 대규모 데이터셋에서 학습된 가중치를 제공
최초 필터의 가중치는 사전 훈련된 모델의 가중치로 초기화
이미 다른 데이터셋에서 학습된 특징을 활용하여 입력 데이터의 특징을 추출할 수 있다.

대각선 필터가 풀링값으로 가장 큰 값으로 구성되어 있다
이미지의 구조에 있어서 대각선 필터와 겹치는 구간이 많았고 풀링 값 숫자겡 반영된것
이미지의 구조는 가로나 세로 필터의 특징보다 대각선의 특징을 많이 갖는다
pooling 값이 크다는 것은 이미지의 특징 값을 상대적으로(0인것에비해) 많이 담고 있는 것

텍스트가 깨져서 수식이 이상하게 보이셨군요! 보기 좋게 정리해서 다시 드릴게요. 마크다운이나 일반 텍스트 환경에서는 수식을 단순히 표현하는 게 더 적절할 수 있어요.

---

## 🔹 ReLU 함수 (Rectified Linear Unit)

**정의**

```
f(x) = x   (x > 0)
f(x) = 0   (x <= 0)
```

**특징**

* 입력이 0보다 크면 그대로 출력
* 0 이하의 값은 모두 0으로 처리 → **음수는 모두 0**

**예시**

* x = 3 → f(x) = 3
* x = -2 → f(x) = 0

---

## 🔹 Leaky ReLU 함수

**정의**

```
f(x) = x           (x > 0)
f(x) = α * x       (x <= 0), 보통 α = 0.01
```

**특징**

* 음수를 0으로 만들지 않고, 아주 작은 값으로 유지
* 즉, **음수도 조금 남긴다**

**예시**

* x = 3 → f(x) = 3
* x = -2 → f(x) = -0.02 (α = 0.01일 때)

---

## 🔸 ReLU vs Leaky ReLU 요약 비교

| 항목    | ReLU           | Leaky ReLU          |
| ----- | -------------- | ------------------- |
| 정의    | x>0이면 x, 아니면 0 | x>0이면 x, 아니면 αx     |
| 음수 처리 | 모두 0           | 아주 작게 남김 (예: 0.01x) |
| 장점    | 간단하고 계산 빠름     | 죽은 뉴런 문제 줄여줌        |
| 단점    | 뉴런이 죽을 수 있음    | α 값 선정 필요           |

---

학습된 필터가 이미지 구조를 반영하기 때문에 대각선이 많은 이미지에서는 풀링 영역에서 대각선 필터가 강력히 작용
이는 풀링 숫자가 커지는 이유로 단순한 숫자보다 대각선 패턴을 담아낸 필터의 역할
이미지의 구조가 대각선 패턴을 더 많이 포함할 때 성립합니다.
모든 이미지에 보편적으로 해당되는 것은 아닙니다

CNN : 이미지의 특징을 추출한 합성곱 과정(convolution layer)
입력 이미지와의 합성곱(filter/stride) > 활성화 함수 > 특징 추출(맥스 풀링)

Input image > Convolution Layers > Fully connected layer > Output(classification)

Convolution Layer : Convolution by kernel > Activation func(Relu) > Max pooling
(필터에 의한 합성곱 이미지는 필터의 개수만큼 생성된다 !!)
CNN : 이미지의 특징을 추출한 합성곱 과정(convolution layer)  
입력 이미지와의 합성곱(filter/stride) > 활성화 함수 > 특징 추출(맥스 풀링)

Convolution Layer : Convolution by kernel (Conv2D) > Activation(Relu) > Max pooling

아래는 이미지에서 추출한 텍스트입니다. 텍스트를 구조적으로 정리하여 드리며, 강조 색상이나 서식은 설명으로 보완했습니다.

---

## 🔹 II. Deep Learning - **Flatten Layer**

### ❖ 정의

> Flatten Layer는 **입력 데이터의 차원을 평탄화(flatten)** 하여 **1차원 벡터로 변환**하는 역할을 합니다.
> 이는 Fully Connected Layer(FC Layer)가 **1차원 입력**을 받기 때문에 필요합니다.

### ❖ 기능 설명

* 이미지나 다차원 데이터를 특징 벡터로 변환.
* 입력 데이터를 **공간적인 구조로 유지**하는 대신, **각 픽셀 정보를 나열**하여 **벡터로 표현**.
* 이후 레이어에서 **패턴 인식** 및 **분류**를 가능하게 함.

### ❖ 시각적 예시 포함

* CNN 구조에서 convolution & pooling 후 → flatten → FC → softmax 순으로 진행.

---

## 🔹 II. Deep Learning - **Softmax (출력층 활성화 함수)**

### ❖ 정의

> CNN에서 **출력층을 구성하는 대표적인 활성화 함수**는 일반적으로 **Softmax 함수**입니다.

### ❖ 기능 설명

* Softmax는 **다중 클래스 분류 문제**에서 클래스별 **확률 분포**를 출력합니다.
* 출력 벡터의 모든 값은 **0\~1 사이의 실수**가 되며, **전체 합은 1**이 됩니다.
* 각 출력 값은 **해당 클래스일 확률**로 해석됩니다.

---

## 🔸 참고 링크

[https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60](https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60)

---

아래는 세 번째 이미지에서 추출한 텍스트를 정리한 내용입니다. 가독성을 높이기 위해 문단 구성과 강조 표현을 일부 정돈하였습니다.

---

## 🔹 II. Deep Learning - **Output Layer (Softmax)**

### ❖ 정의

Softmax 함수는 **다중 클래스 분류 문제**에서 **각 클래스에 속할 확률을 출력**합니다.

* 입력값을 클래스에 대한 확률로 변환
* 출력 값은 **0과 1 사이의 실수**이며, **모든 클래스에 대한 확률의 합은 1**

### ❖ 수식

$$
\text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
$$

### ❖ 예시

| Output layer 값 | Softmax 변환 후 |
| -------------- | ------------ |
| 1.3            | 0.02         |
| 0.2            | 0.07         |
| 2.7            | 0.91         |

🔗 출처: [https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60](https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60)

---

## 🔹 II. Deep Learning - **Back Propagation**

### ❖ 정의

> **예측값과 실제 정답과의 차이 (Loss = 오차 함수)** 를 비교하여 **역방향으로 가중치를 조정**하는 과정.

### ❖ 핵심 설명

* 네트워크의 출력값이 정확해지도록, **오차를 줄이는 방향으로 학습**을 진행.
* **출력층부터 입력층 방향**으로 역전파(backpropagation)를 수행.
* 각 노드의 **기울기(gradient)** 를 계산하여 **가중치를 조정**함.

### ❖ 구성 흐름

1. 순전파(forward) 계산으로 예측값 생성
2. 예측값과 실제값 비교하여 Loss 계산
3. 역전파 수행

   * **가중치의 기울기 계산 (편미분)**
   * **가중치 값 업데이트**
4. 이 과정을 반복하여 네트워크 성능을 향상

🔗 출처: [https://machinelearninggeek.com/backpropagation-neural-network-using-python/](https://machinelearninggeek.com/backpropagation-neural-network-using-python/)

---

conv2D
합성곱의 구현(convolution by kernel)
이미지의 특징을 추출하기 위해 입력 데이터에 필터(커널)를 적용하여 출력을 계산.
컨볼루션 연산은 입력 데이터와 필터 간의 곱셈을 수행하고, 합산하여 출력을 생성
Image Input: 합성곱 연산을 위한 입력 데이터
 예시로 50개의 배치로 30*30크기의 칼라 이미지 입력
파라미터
•filters: 필터의 개수 지정. 출력 채널의 개수
 예시로 필터 4*4, 입력채널 3개, 필터 개수 32개 [4,4,3,32]
•kernel_size: 보통 정사각형 형태로 지정하며, (height, width) 형태로 튜플로 지정.
•strides: 필터를 적용하는 간격 지정. 기본값은 (1, 1)
•padding: 'valid'는 패딩을 사용하지 않음을 의미하고,
 'same'은 출력 크기를 입력과 동일하게 유지하기 위해 패딩을 추가.
•activation: 활성화 함수를 지정. 일반적으로는 ReLU
import tensorflow as tf
# 입력 데이터: shape (batch, height, width, channels)
batch_size = 2
height, width, in_channels = 5, 5, 3
# 무작위 이미지 예시
inputs = tf.random.normal((batch_size, height, width, in_channels))
print("입력 shape:", inputs.shape) # (2, 5, 5, 3)

# Conv2D 레이어
conv = tf.keras.layers.Conv2D(
filters=4, # 출력 채널 수
kernel_size=(3,3), # 필터 크기
strides=(1,1),
padding='same', # 출력 크기 동일
activation=None
)
# Conv 연산 수행
outputs = conv(inputs)
print("출력 shape:", outputs.shape) # (2, 5, 5, 4)

padding='same’ : 입력 이미지의 공간 크기를 출력에서도 유지
입력 채널(RGB) 3개를 하나의 필터가 모두 계산한 뒤,
출력 채널별로 다른 필터로 4개의 결과를 뽑는 과정
batch=2는 모든 과정을 2장에 병렬로 돌리기 때문에 shape 그대로 유지!

개의 출력 채널이 출력 채널을 계산할 때:입력 채널(R, G, B) 각각에 3x3 커널이 있음!
총 3개의 3x3 kernel이 모여서 하나의 출력 채널을 만듦.
출력 채널1 = (입력 채널 R * kernel_R)
 + (입력 채널 G * kernel_G)
 + (입력 채널 B * kernel_B)
출력 채널 4개니까?
•출력 채널 1: R, G, B 3개의 커널셋
•출력 채널 2: R, G, B 3개의 커널셋
•출력 채널 3: R, G, B 3개의 커널셋
•출력 채널 4: R, G, B 3개의 커널셋
출력 채널 4개는 색상채널=3의 결합 특징을 새로운 공간구조로 재배열한 것.
색상은 합산 돼 사라지지만 공각적으로 무슨 특징인지는 출력 채널별로 새로 저장

1️⃣ Conv 연산의 목적: 특징 추출
이미지에는 특징 (edge, corner, texture)가 있음.
Conv 연산은 필터(kernel)를 통해 입력의 일부 영역을 보면서 특징을 추출하는 역할!
예:수평 edge 필터 → 수평 경계 검출
대각선 edge 필터 → 대각선 경계 검출
2️⃣ 곱-합 연산이 특징을 강조!패치-필터 곱-합
패치: 입력의 작은 영역 (ex: 3x3)
필터: 이 패치와 곱-합 → 특징 강조
3️⃣ 채널별로 보존되는 구조
RGB (3채널) 입력
Conv는 채널별로 필터셋을 갖고 → 각 채널 특징을 동시에 계산
그 결과를 합산하여 새로운 출력 채널로 저장!
4️⃣ 특징이 “변환된 형태”로 보존Conv를 거치면 입력 이미지의 픽셀은 없어짐.
대신, 이미지의 edge, texture, corner 같은 특징 정보가 feature map으로 변환되어 살아남음!

batch차원은 항상 있어야 한다
 ((batch_size, height, width, in_channels))
 inputs = tf.random.normal((1,5,5,3)) # batch가 1개라도 batch=1로 처리!
strides, kernel_size는 tuple로 명시(kernel_size=3은 3*3)
 tf.keras.layers.Conv2D(filters=4, kernel_size=3, strides=1, padding='same')
activation 생략은 linear 출력! : 기본적으로 activation=None
PyTorch는 입력 채널 순서가 다르므로 주의!

maxpooling의 구현
입력 데이터에서 지정된 영역 내에서 최댓값을 선택하여 feature map을 다운 샘플링.
•pool_size: (height, width) 형태의 튜플로 지정하며, 정수 값으로도 지정할 수 있다.
•strides: 풀링 영역을 이동하는 간격을 지정. 기본값은 (pool_size[0], pool_size[1])로,
풀링 영역 크기와 동일한 값으로 설정.
•padding:valid 는 패딩을 사용하지 않음,
 same 은 출력 크기를 입력과 동일하게 유지하기 위한 자동 패딩 추가.

 특정 양수값에 수렴하지 않아 특징 추출에 있어서 sigmoid 함수보다 훨씬 더 잘 작동.
빠른 연산 속도
선형함수(ax+b)의 단점 보완, 상수배를 높게 해도 선형함수를 계속 유지 단점
Sigmoid 함수가 역전파 과정에서 미분을 시행하면 0에 가까운 기울기가 발생시,
(미분한 기울기가 그래프의 좌하단/우상단에서 0에 수렴한다 !!)
기울기 소실(vanishing gradient ) 문제를 해결하는 방법으로 등장

옵티마이저 아담
예측치와 실제값의 차이인 오차(손실함수)를 최소화 하기 위한 알고리즘
해당 모델의 매개별수를 조장하며 최적화된 문제 해결 방법을 찾아간다
학습률을 조정하면서 가중치를 업데이트하는 방법.
이동 평균을 사용하여 학습률을 동적으로 조절.
학습률을 자동으로 조절하기 때문에 수렴 속도와 안정성을 향상시킨다.

6만 개의 training 이미지와 1만개의 test 이미지.
- 각 이미지는 손으로 쓴 0 ~ 9 의 숫자들을 스캔한 것
- 28 X 28 픽셀 영역에서 각 픽셀은 0 ~ 255 사이의 값, 회색조 칼라.
- 각 이미지에는 0 ~ 9 까지의 해당 숫자 값이 분류명(label)으로 부여되어 있다
아래는 이미지에서 추출한 내용을 보기 쉽게 정리한 **딥러닝(ANN/CNN) 순서도**입니다. 각 단계마다 필요한 함수와 특징을 설명드렸습니다.

---

## 🧠 Deep Learning 순서도 (ANN/CNN 공통)

### 1. **Data 정의**

```python
from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

* **mnist.load\_data( )**: 손글씨 숫자 이미지 데이터셋 불러오기

---

### 2. **Data 전처리**

```python
x_train = x_train / 255.0  # normalization (Min–Max 정규화)
y_train = to_categorical(y_train)
```

* **정규화(normalization)**: 픽셀 값 0~~255 → 0~~1로 스케일 조정
* **to\_categorical( )**: 라벨을 원-핫 인코딩 처리

---

### 3. **모델링**

```python
model = Sequential()
model.add(...)
```

* **ANN**: `Dense()` 사용
* **CNN**: `Conv2D()`, `MaxPool2D()`, `Flatten()` 사용

---

### 4. **모델 컴파일**

```python
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

* **Loss 종류**

  * 원-핫 인코딩: `categorical_crossentropy`
  * 정수 라벨: `sparse_categorical_crossentropy`

---

### 5. **모델 학습**

```python
model.fit(x_train, y_train, epochs=...)
```

* 학습 시작, 에폭 설정 등

---

### 6. **모델 평가**

```python
model.evaluate(x_test, y_test)
```

* 테스트 데이터로 평가
* 필요 시 **confusion matrix**도 출력 가능

---

항목 ANN (인공신경망) CNN (합성곱신경망)
입력 형태 1D 벡터 (28×28 → 784차원으로 flatten) 2D 이미지 (28×28 유지)
레이어 구성 Dense (Fully Connected) Layer만 사용 Conv + Pool + (Dense) Layer 조합
파라미터 수 많음 (모든 픽셀 연결) 적음 (필터 공유, 지역 수용영역)
학습 속도 빠르지만 학습이 불안정할 수 있음 상대적으로 느리지만 일반화 능력 우수
성능 (정확도) ? ?
특징 추출 방식 수동적 (픽셀 간 관계 반영 어려움) 자동 (필터로 공간적 특징 추출)
과적합 위험 높음 (파라미터 많고 지역정보 손실됨) 낮음 (필터 공유 및 로컬 특성 학습)
시각적 직관성 낮음 (가중치 해석 어려움) 높음 (필터 시각화 가능)
메모리 사용량 큼 (flatten으로 고차원) 효율적 (stride, pooling 등으로 다운샘플링)
실전 사용 이미지보다는 표 형식 데이터에 적합 이미지 처리에 최적화